import boto3
import time
from pathlib import Path

# =========================
# CONFIGURA√á√ïES GERAIS
# =========================
AWS_PROFILE = "pos_dados"
AWS_REGION = "us-east-1"

ATHENA_DATABASE = "lakehouse_curated"
ATHENA_OUTPUT = "s3://pos-graduacao-lakehouse/athena-query-results/"

CURATED_BUCKET = "pos-graduacao-lakehouse"
CURATED_BASE_PREFIX = "curated"


POLL_INTERVAL_SECONDS = 2

# =========================
# RESOLVER PATH DO PROJETO
# =========================
PROJECT_ROOT = Path(__file__).resolve().parents[2]
SQL_FOLDER = PROJECT_ROOT / "sql" / "curated_ctas"

# =========================
# SESS√ÉO AWS
# =========================
session = boto3.Session(
    profile_name=AWS_PROFILE,
    region_name=AWS_REGION
)

athena = session.client("athena")
s3 = session.client("s3")

# =========================
# FUN√á√ÉO: LIMPAR PREFIX S3
# =========================
def limpar_s3_prefix(bucket: str, prefix: str):

    print(f"üßπ Limpando S3: s3://{bucket}/{prefix}")

    paginator = s3.get_paginator("list_objects_v2")
    pages = paginator.paginate(Bucket=bucket, Prefix=prefix)

    objects_to_delete = []

    for page in pages:
        for obj in page.get("Contents", []):
            objects_to_delete.append({"Key": obj["Key"]})

    if objects_to_delete:
        s3.delete_objects(
            Bucket=bucket,
            Delete={"Objects": objects_to_delete}
        )
        print("   ‚úî Dados antigos removidos")
    else:
        print("   ‚Ñπ Nenhum dado antigo encontrado")

# =========================
# FUN√á√ÉO: EXECUTAR 1 SQL
# =========================
def executar_sql_unico(query: str, descricao: str):

    response = athena.start_query_execution(
        QueryString=query,
        QueryExecutionContext={
            "Database": ATHENA_DATABASE
        },
        ResultConfiguration={
            "OutputLocation": ATHENA_OUTPUT
        }
    )

    execution_id = response["QueryExecutionId"]
    print(f"   ‚ñ∂ {descricao} | QueryExecutionId: {execution_id}")

    while True:
        status_response = athena.get_query_execution(
            QueryExecutionId=execution_id
        )

        status = status_response["QueryExecution"]["Status"]["State"]

        if status in ["SUCCEEDED", "FAILED", "CANCELLED"]:
            break

        time.sleep(POLL_INTERVAL_SECONDS)

    if status != "SUCCEEDED":
        reason = status_response["QueryExecution"]["Status"].get(
            "StateChangeReason", "Motivo n√£o informado"
        )
        raise Exception(f"{descricao} falhou: {reason}")

# =========================
# FUN√á√ÉO: EXECUTAR CTAS
# =========================
def executar_ctas(sql_file: Path):

    table_name = sql_file.stem.replace("ctas_", "")
    curated_prefix = f"{CURATED_BASE_PREFIX}/{table_name}/"

    print(f"\nüöÄ Executando CTAS: {sql_file.name}")
    print(f"   üß† Tabela: lakehouse_curated.{table_name}")

    # 1Ô∏è‚É£ Limpar S3
    limpar_s3_prefix(
        bucket=CURATED_BUCKET,
        prefix=curated_prefix
    )

    # 2Ô∏è‚É£ DROP TABLE
    drop_query = f"DROP TABLE IF EXISTS lakehouse_curated.{table_name};"
    executar_sql_unico(
        query=drop_query,
        descricao=f"DROP {table_name}"
    )

    # 3Ô∏è‚É£ CREATE TABLE AS SELECT
    with open(sql_file, "r", encoding="utf-8") as f:
        ctas_query = f.read().strip()

    executar_sql_unico(
        query=ctas_query,
        descricao=f"CTAS {table_name}"
    )

    print(f"   ‚úÖ CTAS conclu√≠da: {table_name}")

# =========================
# EXECU√á√ÉO PRINCIPAL
# =========================
if __name__ == "__main__":

    print("\n==============================")
    print("üèÅ IN√çCIO PIPELINE CURATED")
    print("==============================")

    if not SQL_FOLDER.exists():
        raise FileNotFoundError(f"Pasta SQL n√£o encontrada: {SQL_FOLDER}")

    sql_files = sorted(SQL_FOLDER.glob("*.sql"))

    if not sql_files:
        raise Exception("Nenhum arquivo SQL encontrado")

    print(f"üìÇ Pasta de SQL encontrada:\n   {SQL_FOLDER}")
    print(f"üìÑ CTAS encontradas: {len(sql_files)}")

    for sql_file in sql_files:
        executar_ctas(sql_file)

    print("\nüéâ PIPELINE CURATED FINALIZADO COM SUCESSO")